{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mini Project: Deep Learning with Keras\n",
        "\n",
        "In this mini-project we'll be building a deep learning classifier using Keras to predict income from the popular [Adult Income dataset](http://www.cs.toronto.edu/~delve/data/adult/adultDetail.html).\n",
        "\n",
        "Predicting income from demographic and socio-economic information is an important task with real-world applications, such as financial planning, market research, and social policy analysis. The Adult dataset, sometimes referred to as the \"Census Income\" dataset, contains a vast amount of anonymized data on individuals, including features such as age, education, marital status, occupation, and more. Our objective is to leverage this data to train a deep learning model that can effectively predict whether an individual's income exceeds $50,000 annually or not.\n",
        "\n",
        "Throughout this Colab, we will walk you through the entire process of building a deep learning classifier using Keras, a high-level neural network API that runs on top of TensorFlow. Keras is known for its user-friendly and intuitive interface, making it an excellent choice for both beginners and experienced deep learning practitioners.\n",
        "\n",
        "Here's a brief outline of what we will cover in this mini-project:\n",
        "\n",
        "1. **Data Preprocessing:** We will start by loading and exploring the Adult dataset.\n",
        "\n",
        "2. **Building the Deep Learning Model:** We will construct a neural network using Keras, where we'll dive into understanding the key components of a neural network, including layers, activation functions, and optimization algorithms.\n",
        "\n",
        "3. **Model Training:** With our model architecture in place, we will split the data into training and validation sets and train the neural network on the training data. We will monitor the training process to prevent overfitting and enhance generalization.\n",
        "\n",
        "4. **Model Evaluation:** After training, we'll assess the performance of our model on the test dataset.\n",
        "\n",
        "By the end of this tutorial, you will not only have a functional deep learning classifier for income prediction but also gain valuable insights into how to leverage the power of neural networks for solving real-world classification tasks.\n"
      ],
      "metadata": {
        "id": "fyXucUekO19i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "id": "rAGzXpBhHLPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c03815b-bd59-4d28-b299-564399939e23"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras) (1.6.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kLWR1DfQPakn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can download the Adult data from the link [here](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data).\n",
        "\n",
        "Here are your tasks:\n",
        "\n",
        "  1. Load the Adult data into a Pandas Dataframe.\n",
        "  2. Ensure the dataset has properly named columns. If the columns are not read in, assign them by referencing the dataset documentation.\n",
        "  3. Display the first five rows of the dataset."
      ],
      "metadata": {
        "id": "5ymxgnyq86hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
        "\n",
        "# Download the dataset and load it into a pandas DataFrame"
      ],
      "metadata": {
        "id": "QmwdQy7pShig"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define column names based on UCI Adult Dataset documentation.\n",
        "column_names = [\n",
        "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
        "    \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
        "    \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income\"\n",
        "]\n",
        "\n",
        "# Load the dataset from the specified path.\n",
        "# - `names=column_names` assigns meaningful column names since the dataset lacks a header.\n",
        "# - `skipinitialspace=True` removes leading spaces from values, ensuring clean data.\n",
        "df = pd.read_csv(DATA_PATH, names=column_names, skipinitialspace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "d8Fo3VkkYEuD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame"
      ],
      "metadata": {
        "id": "X1wSIzVtPrfL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows to verify successful loading.\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtSOHPcNYJVD",
        "outputId": "de707919-ed59-4add-c105-3bbb737708c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age         workclass  fnlwgt  education  education_num  \\\n",
            "0   39         State-gov   77516  Bachelors             13   \n",
            "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
            "2   38           Private  215646    HS-grad              9   \n",
            "3   53           Private  234721       11th              7   \n",
            "4   28           Private  338409  Bachelors             13   \n",
            "\n",
            "       marital_status         occupation   relationship   race     sex  \\\n",
            "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
            "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
            "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
            "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
            "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
            "\n",
            "   capital_gain  capital_loss  hours_per_week native_country income  \n",
            "0          2174             0              40  United-States  <=50K  \n",
            "1             0             0              13  United-States  <=50K  \n",
            "2             0             0              40  United-States  <=50K  \n",
            "3             0             0              40  United-States  <=50K  \n",
            "4             0             0              40           Cuba  <=50K  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're not already familiar with the Adult dataset, it's important to do some exploratory data analysis.\n",
        "\n",
        "Here are your tasks:\n",
        "\n",
        "  1. Do exploratory data analysis to give you some better intuition for the dataset. This is a bit open-ended. How many rows/columns are there? How are NULL values represented? What's the percentage of positive cases in the dataset?\n",
        "\n",
        "  2. Drop all rows with NULL values.\n",
        "\n",
        "  3. Use Scikit-Learn's [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) to convert the `income` column with a data type string to a binary variable."
      ],
      "metadata": {
        "id": "5fHLuKZl9ivm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do some exploratory analysis. How many rows/columns are there? How are NULL\n",
        "# values represented? What's the percentrage of positive cases in the dataset?"
      ],
      "metadata": {
        "id": "fc_s4kRKTloe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the shape of the dataset\n",
        "rows, columns = df.shape\n",
        "\n",
        "# Print the number of rows and columns\n",
        "print(f\"Number of rows: {rows}\")\n",
        "print(f\"Number of columns: {columns}\")\n",
        "\n",
        "# Iterate over all columns to analyze their unique values and data types\n",
        "for col in df.columns:\n",
        "    print(f\"{col}: {df[col].unique()[:10]}\")  # Display the first 10 unique values in each column\n",
        "    print(f\"Data type: {df[col].dtype}\")      # Show the data type of the column\n",
        "    print(\"  \")  # Add spacing for better readability\n",
        "\n",
        "#After analizing the data, missing values in categorical columns are represented by question marks\n",
        "\n",
        "# Get the number of positive cases in the 'income' column\n",
        "# Assuming 'income' is a categorical column with two values (e.g., '<=50K' and '>50K'),\n",
        "# df['income'].value_counts() returns the count of each unique value.\n",
        "# The `[1]` index assumes that the second value in the frequency count corresponds to positive cases.\n",
        "print(f\"Number of positive cases: {df['income'].value_counts()[1]}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxQ63U35ZBNa",
        "outputId": "e6398791-85cc-4f65-c1b1-bd786988de6e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 32561\n",
            "Number of columns: 15\n",
            "age: [39 50 38 53 28 37 49 52 31 42]\n",
            "Data type: int64\n",
            "  \n",
            "workclass: ['State-gov' 'Self-emp-not-inc' 'Private' 'Federal-gov' 'Local-gov' '?'\n",
            " 'Self-emp-inc' 'Without-pay' 'Never-worked']\n",
            "Data type: object\n",
            "  \n",
            "fnlwgt: [ 77516  83311 215646 234721 338409 284582 160187 209642  45781 159449]\n",
            "Data type: int64\n",
            "  \n",
            "education: ['Bachelors' 'HS-grad' '11th' 'Masters' '9th' 'Some-college' 'Assoc-acdm'\n",
            " 'Assoc-voc' '7th-8th' 'Doctorate']\n",
            "Data type: object\n",
            "  \n",
            "education_num: [13  9  7 14  5 10 12 11  4 16]\n",
            "Data type: int64\n",
            "  \n",
            "marital_status: ['Never-married' 'Married-civ-spouse' 'Divorced' 'Married-spouse-absent'\n",
            " 'Separated' 'Married-AF-spouse' 'Widowed']\n",
            "Data type: object\n",
            "  \n",
            "occupation: ['Adm-clerical' 'Exec-managerial' 'Handlers-cleaners' 'Prof-specialty'\n",
            " 'Other-service' 'Sales' 'Craft-repair' 'Transport-moving'\n",
            " 'Farming-fishing' 'Machine-op-inspct']\n",
            "Data type: object\n",
            "  \n",
            "relationship: ['Not-in-family' 'Husband' 'Wife' 'Own-child' 'Unmarried' 'Other-relative']\n",
            "Data type: object\n",
            "  \n",
            "race: ['White' 'Black' 'Asian-Pac-Islander' 'Amer-Indian-Eskimo' 'Other']\n",
            "Data type: object\n",
            "  \n",
            "sex: ['Male' 'Female']\n",
            "Data type: object\n",
            "  \n",
            "capital_gain: [ 2174     0 14084  5178  5013  2407 14344 15024  7688 34095]\n",
            "Data type: int64\n",
            "  \n",
            "capital_loss: [   0 2042 1408 1902 1573 1887 1719 1762 1564 2179]\n",
            "Data type: int64\n",
            "  \n",
            "hours_per_week: [40 13 16 45 50 80 30 35 60 20]\n",
            "Data type: int64\n",
            "  \n",
            "native_country: ['United-States' 'Cuba' 'Jamaica' 'India' '?' 'Mexico' 'South'\n",
            " 'Puerto-Rico' 'Honduras' 'England']\n",
            "Data type: object\n",
            "  \n",
            "income: ['<=50K' '>50K']\n",
            "Data type: object\n",
            "  \n",
            "Number of positive cases: 7841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-24c7b6121818>:20: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  print(f\"Number of positive cases: {df['income'].value_counts()[1]}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all NULL values and drop them"
      ],
      "metadata": {
        "id": "pZW7GRw3P0dT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace \"?\" with NaN for better handling of missing values\n",
        "df.replace(\"?\", pd.NA, inplace=True)\n",
        "\n",
        "# Drop rows where any column has NaN values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Reset index after dropping rows\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "7Vw-fxPg_EUO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Scikit-Learn's LabelEncoder to convert the income column with a data type\n",
        "# string to a binary variable."
      ],
      "metadata": {
        "id": "BZ_mJT_DLZ-L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the 'income' column\n",
        "df[\"income\"] = encoder.fit_transform(df[\"income\"])"
      ],
      "metadata": {
        "id": "H0urDrWrAlpC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Split the data into training and test sets. Remember not to include the label you're trying to predict, `income`, as a column in your training data."
      ],
      "metadata": {
        "id": "ibK0DxJsA1JH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and test sets"
      ],
      "metadata": {
        "id": "1whzL6K7J-zq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features (X) and target variable (y)\n",
        "X = df.drop('income', axis=1)  # Features (everything except 'income')\n",
        "y = df['income']  # Target variable ('income')\n",
        "\n",
        "# Split data into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "BlE8O01xmpoy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In machine learning, the Receiver Operating Characteristic (ROC) curve and the Area Under the Curve (AUC) metric are commonly used to evaluate the performance of binary classification models. These are valuable tools for understanding how well a model can distinguish between the positive and negative classes in a classification problem.\n",
        "\n",
        "Let's break down each concept:\n",
        "\n",
        "1. ROC Curve:\n",
        "The ROC curve is a graphical representation of a binary classifier's performance as the discrimination threshold is varied. It is created by plotting the True Positive Rate (TPR) against the False Positive Rate (FPR) at different threshold values. Here's how these rates are calculated:\n",
        "\n",
        "- True Positive Rate (TPR), also called Sensitivity or Recall, measures the proportion of actual positive instances that are correctly identified by the model:\n",
        "   TPR = True Positives / (True Positives + False Negatives)\n",
        "\n",
        "- False Positive Rate (FPR) measures the proportion of actual negative instances that are incorrectly classified as positive by the model:\n",
        "   FPR = False Positives / (False Positives + True Negatives)\n",
        "\n",
        "The ROC curve is useful because it shows how well a classifier can trade off between sensitivity and specificity across different threshold values. The ideal ROC curve hugs the top-left corner, indicating a high TPR and low FPR, meaning the classifier is excellent at distinguishing between the two classes.\n",
        "\n",
        "2. AUC (Area Under the Curve):\n",
        "The AUC is a scalar metric derived from the ROC curve. It represents the area under the ROC curve, hence its name. The AUC ranges from 0 to 1, where 0 indicates a very poor classifier (always predicting the opposite class) and 1 signifies a perfect classifier (making all correct predictions).\n",
        "\n",
        "The AUC metric is beneficial because it provides a single value to summarize the classifier's overall performance across all possible threshold values. It is particularly useful when dealing with imbalanced datasets, where one class significantly outnumbers the other. In such cases, accuracy alone might not be a reliable evaluation metric, and AUC can provide a more robust performance measure.\n",
        "\n",
        "A quick rule of thumb for interpreting AUC values:\n",
        "- AUC ≈ 0.5: The model performs no better than random guessing.\n",
        "- 0.5 < AUC < 0.7: The model has poor to fair performance.\n",
        "- 0.7 < AUC < 0.9: The model has good to excellent performance.\n",
        "- AUC ≈ 1: The model is close to or has a perfect performance."
      ],
      "metadata": {
        "id": "HMsXM6B_BX5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are your tasks:\n",
        "\n",
        "  1. Use Scikit-Learn's [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) to calculate the AUC score for a method that always predicts the majority class.  "
      ],
      "metadata": {
        "id": "NDGgBVEKEYKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Scikit-Learn's roc_auc_score to calculate the AUC score for a method that\n",
        "# always predicts the majority class."
      ],
      "metadata": {
        "id": "s00Xs8bqUZnn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the most frequent class in the training labels\n",
        "majority_class = y_train.value_counts().idxmax()\n",
        "\n",
        "# Create an array of predictions (all assigned to the majority class)\n",
        "y_pred_majority = np.full(shape=y_test.shape, fill_value=majority_class)\n",
        "\n",
        "# Compute the AUC score\n",
        "auc_score = roc_auc_score(y_test, y_pred_majority)"
      ],
      "metadata": {
        "id": "3zyrkRqWrFdt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's do a little feature engineering.\n",
        "\n",
        "1. Use Scikit-Learn's [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) to apply One Hot Encoding to the categorical variables in `workclass`, `education`, `marital-status`, `occupation`, `relationship`, 'race', `sex`, and `native-country`. Also, apply [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) to the remaining continuous features. How many columns will the dataframe have after these columns transformations are applied?"
      ],
      "metadata": {
        "id": "uWSiYNarF2t_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Scikit-Learn's ColumnTransformer to apply One Hot Encoding to the\n",
        "# categorical variables in workclass, education, marital-status, occupation,\n",
        "# relationship, 'race', sex, and native-country. #Also, apply MinMaxScaler to\n",
        "# the remaining continuous features."
      ],
      "metadata": {
        "id": "4DybgGJyW-3Q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define categorical and continuous columns\n",
        "categorical_columns = ['workclass', 'education', 'marital_status', 'occupation',\n",
        "                       'relationship', 'race', 'sex', 'native_country']\n",
        "continuous_columns = ['age', 'fnlwgt', 'education_num', 'capital_gain',\n",
        "                      'capital_loss', 'hours_per_week']\n",
        "\n",
        "# Create a ColumnTransformer to preprocess data\n",
        "column_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        # Apply One-Hot Encoding to categorical columns (ignores unknown categories)\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns),\n",
        "\n",
        "        # Apply MinMax Scaling to continuous columns (scales values between 0 and 1)\n",
        "        ('cont', MinMaxScaler(), continuous_columns)\n",
        "    ],\n",
        "    remainder='passthrough'  # Keep any other columns unchanged\n",
        ")"
      ],
      "metadata": {
        "id": "qcFHUXU6svQH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many columns will the dataframe have after these columns transformations are applied?"
      ],
      "metadata": {
        "id": "emfaqHwvKfLU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit and transform the dataset\n",
        "X_transformed = column_transformer.fit_transform(X)\n",
        "\n",
        "# Get feature names after transformation\n",
        "encoded_cat_columns = column_transformer.named_transformers_['cat'].get_feature_names_out(categorical_columns)\n",
        "new_column_names = list(encoded_cat_columns) + continuous_columns  # Combine encoded and scaled columns\n",
        "\n",
        "# Convert the transformed NumPy array back to a DataFrame\n",
        "X_transformed_df = pd.DataFrame(X_transformed, columns=new_column_names)\n",
        "\n",
        "# Get the shape of the transformed DataFrame to count the totals of new columns\n",
        "#new_total_columns = X_transformed_df.shape[1]\n",
        "#print(f\"Total columns after transformations: {new_total_columns}\")"
      ],
      "metadata": {
        "id": "CPzno7cNtvtg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras is an open-source deep learning library written in Python. It was developed to provide a user-friendly, high-level interface for building and training neural networks. The library was created by François Chollet and was first released in March 2015 as part of the Deeplearning4j project. Later, it became part of the TensorFlow ecosystem and is now the official high-level API for TensorFlow.\n",
        "\n",
        "Keras is designed to be modular, user-friendly, and easy to extend. It allows researchers and developers to quickly prototype and experiment with various deep learning models. One of the primary goals of Keras is to enable fast experimentation, making it simple to build and iterate on different architectures.\n",
        "\n",
        "Key features of Keras include:\n",
        "\n",
        "1. User-friendly API: Keras provides a simple and intuitive interface for defining and training deep learning models. Its design philosophy focuses on ease of use and clarity of code.\n",
        "\n",
        "2. Modularity: Models in Keras are built as a sequence of layers, and users can easily stack, merge, or create complex architectures using a wide range of predefined layers.\n",
        "\n",
        "3. Extensibility: Keras allows users to define custom layers, loss functions, and metrics. This flexibility enables researchers to experiment with new ideas and algorithms seamlessly.\n",
        "\n",
        "4. Backends: Initially, Keras supported multiple backends, including TensorFlow, Theano, and CNTK. However, as of TensorFlow version 2.0, TensorFlow has become the primary backend for Keras.\n",
        "\n",
        "5. Multi-GPU and distributed training: Keras supports training models on multiple GPUs and in distributed computing environments, making it suitable for large-scale experiments.\n",
        "\n",
        "6. Pre-trained models: Keras includes a collection of pre-trained models for common tasks, such as image classification (e.g., VGG, ResNet, MobileNet) and natural language processing (e.g., Word2Vec, GloVe).\n",
        "\n",
        "The integration of Keras into TensorFlow as its official high-level API has solidified its position as one of the most popular deep learning libraries in the machine learning community. Its ease of use and versatility have contributed to its widespread adoption in both academia and industry for a wide range of deep learning tasks."
      ],
      "metadata": {
        "id": "AtoqTz5rGuET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are your tasks:\n",
        "\n",
        "1. Create your own model in Keras to predict income in the Adult training data. Remember, it's always better to start simple and add complexity to the model if necessary. What's a good loss function to use?\n",
        "\n",
        "2. Keras can be integrated with Scitkit-Learn using a wrapper. Use the [KerasClassifier wrapper](https://adriangb.com/scikeras/stable/generated/scikeras.wrappers.KerasClassifier.html) to integrate your Keras model with the ColumnTransformer from previous steps using a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) object.\n",
        "\n",
        "3. Fit your model.\n",
        "\n",
        "4. Calculate the AUC score of your model on the test data. Does the model predict better than random?\n",
        "\n",
        "5. Generate an ROC curve for your model using [RocCurveDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html). What would the curve look like if all your predictions were randomly generated? What would the curve look like if it you had a perfect model?"
      ],
      "metadata": {
        "id": "HVUa0h83HU24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Keras model"
      ],
      "metadata": {
        "id": "h2xIpLlXQEcx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Keras classifier"
      ],
      "metadata": {
        "id": "Rz-m2LhrQGud"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the scikit-learn pipeline"
      ],
      "metadata": {
        "id": "VKxkil7QQJ6n"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the pipeline on the training data"
      ],
      "metadata": {
        "id": "25O8ZLleGQnk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the AUC score of your model on the test data.\n",
        "# Does the model predict better than random?"
      ],
      "metadata": {
        "id": "SLcNQGVqNYbB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate an ROC curve for your model."
      ],
      "metadata": {
        "id": "prJG9pr7PYIc"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}